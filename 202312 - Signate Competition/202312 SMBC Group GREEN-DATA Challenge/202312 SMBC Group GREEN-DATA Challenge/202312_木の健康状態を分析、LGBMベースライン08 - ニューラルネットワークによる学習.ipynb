{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# åˆ†å¸ƒç¢ºèªã«ä½¿ã†\n",
    "#import pandas_profiling as pdp\n",
    "# å¯è¦–åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "# å‰å‡¦ç†ã€ç‰¹å¾´é‡ä½œæˆ - sklearnã‚’ä½¿ã†\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "# ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒ»ç²¾åº¦ã¨è©•ä¾¡æŒ‡æ¨™\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "#LGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# NOTE matplotã§ã®æ—¥æœ¬èªæ–‡å­—åŒ–ã‘ã‚’è§£æ¶ˆ\n",
    "#pip install japanize-matplotlib\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col=0) # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿\n",
    "test = pd.read_csv(\"test.csv\", index_col=0) # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿   # è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿\n",
    "sample_submit = pd.read_csv(\"sample_submission.csv\", index_col=0, header=None) # å¿œå‹Ÿç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ï¼š\")\n",
    "print(train.shape)\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿æ•°ï¼š\")\n",
    "print(len(train))\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ©ãƒ æ•°\")\n",
    "print(len(train.columns))\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å‹ä¸€è¦§\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚³ãƒ©ãƒ æ•°ã¯å…¨éƒ¨ã§20å€‹ã€‚ãƒ€ãƒŸãƒ¼åŒ–ã§ãã‚‹ã‚‚ã®ã¯ãƒ€ãƒŸãƒ¼åŒ–ã€ãã†ã§ãªã„ã‚‚ã®ã¯åˆ†å¸ƒæ•°ã®å¤šã„ã‚‚ã®ã®ã¿ã‚’å–ã‚Šå‡ºã™ãªã©ã®å·¥å¤«ã‚’ã—ã¦\n",
    "ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’ä½¿ã£ãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ãƒ‡ãƒ¼ã‚¿å‹ä¸€è¦§\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree_dbh, health, borocode, boro_ct, cb_num, st_senate, st_assem, cncldistã§\n",
    "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹ã€‚ãã®ä»–æœ¬æ¥ãªã‚‰intå‹ã«ã™ã‚‹ã¹ãå€¤ã‚‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ç”¨ã„ã‚‹\n",
    "\n",
    "tree_dbh - æœ¨ã®å††å‘¨ã€‚é‡çš„å¤‰æ•°\n",
    "health - æœ¨ã®å¥åº·çŠ¶æ…‹ã€ç›®çš„å¤‰æ•°\n",
    "borocode - ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã®è¡Œæ”¿åŒºåˆ†ã€‚è³ªçš„å¤‰æ•°\n",
    "boro_ct - ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°ã€‚è³ªçš„å¤‰æ•°\n",
    "cb_num - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒœãƒ¼ãƒ‰ç•ªå·ã€‚è³ªçš„å¤‰æ•°\n",
    "st_senate - å·ä¸Šé™¢åœ°åŒºç•ªå·ã€‚è³ªçš„å¤‰æ•°\n",
    "st_assem - å·è­°ä¼šåœ°åŒºç•ªå·ã€‚è³ªçš„å¤‰æ•°\n",
    "cncldist - å¸‚è­°ä¼šã®åœ°åŒºç•ªå·ã€‚è³ªçš„å¤‰æ•°\n",
    "\n",
    "â†’ä½¿ãˆã‚‹ã®ã¯tree_dbhã ã‘ã€‚\n",
    "æ¬¡ã¯strãƒ»objectå‹ã‹ã‚‰intãƒ»floatå‹ã«å¤‰æ›ã™ã‚‹ã¹ãã‚‚ã®ã‚’æ¢ã™\n",
    "\n",
    "steward â†’ æœ¨ã®ç®¡ç†è€…æ•° \n",
    "stewardã¯ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹ã€‚\n",
    "\n",
    "tree_dbh,stewardã®ä»–ã«ã‚‚ã¾ãšã¯ç°¡å˜ã«ãƒ€ãƒŸãƒ¼åŒ–ã§ãã‚‹å¤‰æ•°5ã¤ã‚’ä½¿ã£ã¦ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ©ãƒ æ•°\")\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ©ãƒ æ•°\")\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"health\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.plot.bar(\"health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç›®çš„å¤‰æ•°ã¯1(good)ã§ã‚ã‚‹ã“ã¨ãŒæ®†ã©ã ãŒã€0ã‚„2(normal, bad)ãŒç´„20%ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"curb_loc\"].value_counts()\n",
    "print(counts)\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"curb_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"steward\"].value_counts()\n",
    "print(counts)\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"steward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"guards\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"guards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"sidewalk\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"sidewalk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"user_type\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"user_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tree_dbh\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â†’ ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã«è¿‘ã„ã€‚æŒ‡æ•°åŒ–ã™ã‚Œã°ã‚ˆã‚Šæœ‰åŠ¹ãªå€¤ã«ãªã‚‹ã‹ã‚‚ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "counts = train[\"problems\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "prob_counts = train[\"problems\"].value_counts()\n",
    "print(prob_counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "prob_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_counts = train[\"spc_common\"].value_counts()\n",
    "print(spc_counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "spc_counts.plot.bar(\"spc_common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ¨ã®ç¨®é¡ - æœ€åˆã®10ã‚’ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹\n",
    "counts[:15].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train[\"spc_latin\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"spc_latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ¨ã®ç¨®é¡ - æœ€åˆã®10ã‚’ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹\n",
    "counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#åœ°åŸŸï¼ˆNeighborhood Tabulation Areaï¼‰ã®ç•¥ç§°\n",
    "counts = train[\"nta\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"nta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#åœ°åŸŸï¼ˆNeighborhood Tabulation Areaï¼‰ã®ç•¥ç§°\n",
    "counts = train[\"nta_name\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"nta_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vill, beach, side, hill, park, water, bay, gardenãªã©æœ¨ã«å½±éŸ¿ã—ãã†ãªåç§°ã‚’æŠ½å‡ºã™ã‚‹ã‹ï¼Ÿï¼Ÿ\n",
    "counts[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®ã‚³ãƒ¼ãƒ‰\n",
    "#ãƒœãƒ­ã‚³ãƒ¼ãƒ‰ã¯éå¸¸ã«æœ‰ç›Šãã†ã€‚é‡çš„å¤‰æ•°ã«ã™ã‚‹\n",
    "counts = train[\"borocode\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"borocode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train[\"boro_ct\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"boro_ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°\n",
    "#ã€€ãƒœãƒ­ãƒ¼åç§°ã¯æœ‰åŠ¹ãã†ã€‚ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "\n",
    "counts = train[\"boroname\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"boroname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€éƒµä¾¿ç•ªå·ã«é–¢é€£ã™ã‚‹éƒ½å¸‚ã¾ãŸã¯åœ°åŒº\n",
    "#ã€€æœ€åˆã®5-10å€‹ã‚’ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹ã‹??\n",
    "# é »åº¦ã‚’é‡çš„å¤‰æ•°ã«ã™ã‚‹ã€ãªã©ã‚ˆã‚Šæœ‰åŠ¹ãªãƒ€ãƒŸãƒ¼åŒ–ã‚‚æ¤œè¨ä¸­\n",
    "\n",
    "counts = train[\"zip_city\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"zip_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°\n",
    "#ã€€ãƒœãƒ­ãƒ¼åç§°ã¯æœ‰åŠ¹ãã†ã€‚ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "\n",
    "counts = train[\"cb_num\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"cb_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°\n",
    "#ã€€ãƒœãƒ­ãƒ¼åç§°ã¯æœ‰åŠ¹ãã†ã€‚ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "\n",
    "counts = train[\"st_senate\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"st_senate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°\n",
    "#ã€€ãƒœãƒ­ãƒ¼åç§°ã¯æœ‰åŠ¹ãã†ã€‚ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "\n",
    "counts = train[\"st_assem\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"st_assem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡Œæ”¿åŒºåˆ†ï¼ˆãƒœãƒ­ãƒ¼ï¼‰ã®åç§°\n",
    "#ã€€ãƒœãƒ­ãƒ¼åç§°ã¯æœ‰åŠ¹ãã†ã€‚ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "\n",
    "counts = train[\"cncldist\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"cncldist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä½œæˆã«ç”¨ã„ã‚‹å¤‰æ•°\n",
    "tree_dbh\n",
    "curb_loc\n",
    "steward\n",
    "guards\n",
    "sidewalk\n",
    "user_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ™‚æœŸåˆ—ãƒ‡ãƒ¼ã‚¿\n",
    "ãƒ»è¨˜éŒ²ã•ã‚ŒãŸå¹´ãƒ»æœˆã‚’åˆ†æã«å«ã‚ã‚‹\n",
    "ãƒ»å­£ç¯€ã‚’èª¬æ˜å¤‰æ•°ã«å«ã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ãƒ‡ãƒ¼ã‚¿å‹ä¸€è¦§\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"datetime\"] = pd.to_datetime(train[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¹´ãƒ»æœˆã‚’å–å¾—\n",
    "train[\"datetime\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year\"] = train[\"datetime\"].dt.year\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"month\"] = train[\"datetime\"].dt.month\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year_month\"] = train[\"datetime\"].dt.strftime(\"%Y-%m\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE å¹´æœˆã‚’å­£ç¯€ã«å¤‰æ›\n",
    "def to_season(num):\n",
    "    season = \"winter\"\n",
    "    if (3 <= num <= 5):\n",
    "        season = \"spring\"\n",
    "    elif (6 <= num <= 8):\n",
    "        season = \"summer\"\n",
    "    elif (9 <= num <= 11):\n",
    "        season = \"autumn\"\n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"season\"] = pd.Categorical(train[\"month\"].apply(to_season))\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [\"tree_dbh\",\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"bool_problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\",\"season\"]\n",
    "# x_list = [\"tree_dbh\",\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"bool_problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\"]\n",
    "y_list = [\"health\"]\n",
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "éå­¦ç¿’å¯¾ç­–ã¨ã—ã¦train['health']ã‹ã‚‰1ã®æ•°ã‚’æ¸›ã‚‰ã™\n",
    "â†’ ã“ã®æ–¹æ³•ã¯é€†åŠ¹æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = train['health'].value_counts()\n",
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1ã®å‰²åˆï¼š\")\n",
    "print(\"\" + str(float( train_values[1] / train['health'].value_counts().sum() ) * 100) + \" %\")\n",
    "\n",
    "print(\"0ã®å‰²åˆï¼š\")\n",
    "print(\"\" + str(float( train_values[0] / train['health'].value_counts().sum() ) * 100) + \" %\")\n",
    "\n",
    "print(\"2ã®å‰²åˆï¼š\")\n",
    "print(\"\" + str(float( train_values[2] / train['health'].value_counts().sum() ) * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ¨ã®å¥åº·çŠ¶æ…‹ï¼ˆç›®çš„å¤‰æ•°ï¼‰\n",
    "0:Fairï¼ˆæ™®é€šï¼‰ 1:Goodï¼ˆè‰¯ã„ï¼‰ 2:Poorï¼ˆæ‚ªã„ï¼‰\n",
    "0:è‰¯ã„ã€1:æ™®é€šã€2:æ‚ªã„ã€ã¨ã„ã†å€¤ã«ç½®ãæ›ãˆã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['health'] = train['health'].map({0:1, 1:0, 2:2})\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problemsã‚’boolå¤‰æ› â†’ å•é¡ŒãŒã‚ã‚‹ã‹å¦ã‹ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "train['bool_problems'] = train['problems'].apply(lambda x: 0 if x=='NULL' else 1)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€èª¬æ˜å¤‰æ•°+ç›®çš„å¤‰æ•°ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆ\n",
    "X_train, y_train = train[x_list], train[y_list]\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"datetime\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"year\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"month\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"year_month\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¨ã®çŠ¶æ…‹ã¯å†¬ãƒ»æ¢…é›¨ãƒ»å¤é–‹ã‘ã«æ‚ªããªã‚‹?\n",
    "\n",
    "â†’ãã®æœˆã®ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã®å¹³å‡æ°—æ¸©ãƒ»å¹³å‡æ¹¿åº¦ãƒ»å¹³å‡é™æ°´é‡ãªã©ã‚’åˆ†æè¦å› ã«åŠ ãˆã‚‹\n",
    "5,6,9,10,1,2ã«çŠ¶æ…‹ã®æ‚ªã„æœ¨ãŒå¢—ãˆã‚‹ã®ãŒå…±é€šã—ã¦ã„ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"season\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â†’ã€€æ¬ æå€¤ã¯'NULL'ã¨ã„ã†ã‚«ãƒ†ã‚´ãƒªã«ç½®ãæ›ãˆã€æ¬ æã§ã‚ã‚‹ã¨ã„ã†æƒ…å ±=è³ªçš„å¤‰æ•°ã®1ã¤ã¨ã—ã¦å‡¦ç†ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"steward\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ\n",
    "0ã®æ•°ã‚’åŠåˆ†ã«å‰Šæ¸›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "strategy = {0:7500, 1:3535, 2:698}\n",
    "\n",
    "sample_exe = RandomUnderSampler(random_state=0, sampling_strategy = strategy)\n",
    "X_resampled, y_resampled = sample_exe.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€æœ¨ã®ç›´å¾„ã¨healthã®é–¢ä¿‚\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='health', y='tree_dbh', data=train)\n",
    "plt.title('æœ¨ã®å††å‘¨ãƒ»æœ¨ã®å¥åº·çŠ¶æ…‹ã®ç®±ã²ã’å›³')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â†’ badãªæœ¨ã¯è‹¥å¹²å††å‘¨ãŒå¤§ãã„ã€‚è‚²ã¡ã™ãç­‰ã®åŸå› ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»Šå›ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "\n",
    "x_list = [\"tree_dbh\", \"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]\n",
    "y_list = [\"health\"]\n",
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]\n",
    "\n",
    "- [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]ã‚’ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹\n",
    "- \"problems\"ã‚’ãƒ€ãƒŸãƒ¼åŒ–ã™ã‚‹ã€‚ãã®éš›æœ€åˆã®10è¡Œã ã‘ã‚’æ®‹ã™\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å°‘æ•°ã®è³ªçš„å¤‰æ•°ã‚’ãƒ€ãƒŸãƒ¼åŒ–\n",
    "[\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\",\"season\"]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns = dummy_list, drop_first=False)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è³ªçš„å¤‰æ•°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "ã¾ãšå„ã‚³ãƒ©ãƒ ã®å¹³å‡å€¤ã‚’æ±‚ã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸€æŒ™ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "cols = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\"]\n",
    "for col in cols:\n",
    "    column_means = train.groupby(col)[\"health\"].mean(\"health\")\n",
    "    column_means\n",
    "    \n",
    "    colname = col + \"_tg_enc\"\n",
    "    \n",
    "    X_train[colname] = train[col].map(column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems, spc_commonã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
    "drop_col = [\"problems\",\"spc_common\",\"nta\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\"]\n",
    "\n",
    "X_train = X_train.drop(drop_col , axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "colormap = plt.cm.RdBu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr, square=True, \n",
    "            cmap=colormap, \n",
    "            linecolor='white', annot=False,\n",
    "            vmin=1.0, vmax=-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "ç­‰å€ã«ã™ã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ã¯é€†åŠ¹æœã€‚\n",
    "1, 2ã®æ•°ã‚’å€ã«ã—ã¦ç²¾åº¦å‘ä¸Šã™ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "strategy = {0:15751, 1:3535*2, 2:698*2}\n",
    "sm = SMOTE(sampling_strategy = strategy)\n",
    "\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()\n",
    "\n",
    "X_train, y_train = X_resampled, y_resampled\n",
    "X_train.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨™æº–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_std = pd.DataFrame(std_scaler.transform(X_train), columns=X_train.columns)\n",
    "X_train_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç‰¹å¾´é‡é¸æŠ\n",
    "å­¦ç¿’ã«ä½¿ã†ç‰¹å¾´é‡ã‚’çµã‚‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# estimatorã¨ã—ã¦GBDTã‚’ä½¿ç”¨ã€‚ç‰¹å¾´é‡ã‚’20å€‹é¸æŠ\n",
    "selector = RFE(GradientBoostingRegressor(n_estimators=100, random_state=10), n_features_to_select=35)\n",
    "selector.fit(X_train_std, y_train)\n",
    "mask = selector.get_support()\n",
    "#print(X.feature_names)\n",
    "print(mask)\n",
    "\n",
    "# é¸æŠã—ãŸç‰¹å¾´é‡ã®åˆ—ã®ã¿å–å¾—\n",
    "X_selected = selector.transform(X_train_std)\n",
    "print(\"X.shape={}, X_selected.shape={}\".format(X_train_std.shape, X_selected.shape))\n",
    "\n",
    "list = []\n",
    "not_selected = []\n",
    "columns = X_train_std.columns\n",
    "\n",
    "for i in range(0, len(mask)):\n",
    "    \n",
    "    value = mask[i]\n",
    "    \n",
    "    if (value == True):\n",
    "        list.append(columns[i])\n",
    "    else:\n",
    "        not_selected.append(columns[i])\n",
    "\n",
    "print(\"é¸æŠã•ã‚ŒãŸ25ã®ç‰¹å¾´é‡ï¼š\")\n",
    "print(list)\n",
    "\n",
    "print(\"é¸æŠã•ã‚Œãªã‹ã£ãŸç‰¹å¾´é‡ï¼š\")\n",
    "print(not_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'boro_ct_tg_enc'ã‚’ãƒªã‚¹ãƒˆã‹ã‚‰çœã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25ã«çµã£ãŸX_train_stdã®å¤‰æ•°ã‚’æ¬¡å…ƒåœ§ç¸®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "X_pca = pca.fit_transform(X_train_std)\n",
    "X_pca.shape\n",
    "\n",
    "X_tsne_nc = TSNE(learning_rate = 100).fit_transform(X_train_std)\n",
    "print(X_tsne_nc[:5, :5])\n",
    "print(\"--- X_tsne_nopca ---\")\n",
    "\n",
    "X_tsne = TSNE(learning_rate = 100).fit_transform(X_pca)\n",
    "print(X_tsne[:5, :5])\n",
    "print(\"--- X_tsne ---\")\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.scatter(X_train_std[\"tree_dbh\"], X_train_std[\"problems_tg_enc\"],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(X_tsne_nc[:,0], X_tsne_nc[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.scatter(X_train_std[\"tree_dbh\"], X_train_std[\"problems_tg_enc\"],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(X_tsne_nc[:,0], X_tsne_nc[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1],c = y_train[\"health\"], alpha = 0.25,cmap='plasma')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1],c = y_train[\"health\"], alpha = 0.25,cmap='plasma')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ¤œè¨¼ - å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†å‰²ã‚’1é€šã‚Šæ±ºã‚ã‚‹\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_train_std[list], y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "print(\"å­¦ç¿’ç”¨ãƒ»è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ï¼š\")\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(X_va.shape)\n",
    "print(y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ¤œè¨¼(æ¬¡å…ƒåœ§ç¸®ã—ãŸğŸ…‚ãƒ‡ãƒ¼ã‚¿)\n",
    "X_tr_dr, X_va_dr, y_tr_dr, y_va_dr = train_test_split(X_tsne, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "print(\"å­¦ç¿’ç”¨ãƒ»è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ï¼š\")\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(X_va.shape)\n",
    "print(y_va.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹å­¦ç¿’ + ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–\n",
    "def model_neuralnet(INPUT_SHAPE = X_tr.shape[1]):\n",
    "    \n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    DU_01 = 50\n",
    "    DO_01 = 0.3\n",
    "    DU_02 = 50\n",
    "    DO_02 = 0.2\n",
    "    DU_03 = 10\n",
    "    DO_03 = 0.1\n",
    "    \n",
    "    input_num = Input(shape = (INPUT_SHAPE, ))\n",
    "    \n",
    "    x_num = Dense(DU_01, activation = \"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_01)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_02, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_02)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_03, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_03)(x_num)\n",
    "    \n",
    "    out = Dense(3, activation = \"softmax\")(x_num)\n",
    "    model = Model(inputs = input_num, outputs = out, )\n",
    "    model.compile(optimizer = \"Adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "model_nn = model_neuralnet()\n",
    "model_nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_nn.fit(X_tr, y_tr, batch_size=200, epochs=20, validation_data=(X_va, y_va), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracyã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(result.history['accuracy'], label='train')\n",
    "plt.plot(result.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "# Lossã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure()\n",
    "plt.title('categorical_crossentropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(result.history['loss'], label='train')\n",
    "plt.plot(result.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model_nn.predict(X_tr)\n",
    "y_va_pred = model_nn.predict(X_va)\n",
    "\n",
    "#äºˆæ¸¬ç¢ºç‡ã‚’æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã«å¤‰æ›\n",
    "y_tr_pred = np.argmax(y_tr_pred, axis=1)\n",
    "y_va_pred = np.argmax(y_va_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«ç²¾åº¦:\")\n",
    "print(\"å­¦ç¿’ç²¾åº¦\")\n",
    "print(metric_tr)\n",
    "print(\"æ¤œè¨¼ç²¾åº¦\")\n",
    "\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "valid_f1 = f1_score(y_va, y_va_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹å­¦ç¿’ + ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–\n",
    "def model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1], DU_01=50, DO_01=0.3, DU_02=50, DO_02=0.2, DU_03=10, DO_03=0.1,BATCH=32):\n",
    "    \n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    DU_01 = 50\n",
    "    DO_01 = 0.3\n",
    "    DU_02 = 50\n",
    "    DO_02 = 0.2\n",
    "    DU_03 = 10\n",
    "    DO_03 = 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    input_num = Input(shape = (INPUT_SHAPE, ))\n",
    "    \n",
    "    x_num = Dense(DU_01, activation = \"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_01)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_02, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_02)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_03, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_03)(x_num)\n",
    "    \n",
    "    out = Dense(3, activation = \"softmax\")(x_num)\n",
    "    model = Model(inputs = input_num, outputs = out, )\n",
    "    model.compile(optimizer = \"Adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    \n",
    "# ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ã‚’æœ€å¤§åŒ–ã•ã›ã‚‹\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§æ¢ç´¢ã™ã‚‹æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    params_tuning = {\n",
    "        \"DU_01\": trial.suggest_int(\"DU_01\", 10, 100),\n",
    "        \"DO_01\":trial.suggest_float(\"DO_01\", 0.1, 0.3),\n",
    "        \"DU_02\": trial.suggest_int(\"DU_02\", 10, 100),\n",
    "        \"DO_02\":trial.suggest_float(\"DO_02\", 0.1, 0.3),\n",
    "        \"DU_03\": trial.suggest_int(\"DU_03\", 3, 30),\n",
    "        \"DO_03\":trial.suggest_float(\"DO_03\", 0.1, 0.3),\n",
    "        \n",
    "        \"BATCH\": trial.suggest_int(\"batch\", 64, 128),\n",
    "        # \"optimizer\":trial.suggest_categorical(\"optimizer\",[\"Adam\",\"SGD\"])\n",
    "    }\n",
    "\n",
    "    # ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ¤œè¨¼ - å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†å‰²ã‚’1é€šã‚Šæ±ºã‚ã‚‹\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X_train[list], y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "        \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "    model_nn = model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1], **params_tuning)\n",
    "    #model_nn.summary()\n",
    "        \n",
    "    model_nn.fit(X_tr, y_tr, batch_size=params_tuning[\"BATCH\"], epochs=20, validation_data=(X_va, y_va), verbose=1\n",
    "                    #early_stopping_rounds=100, \n",
    "                    #verbose=0\n",
    "                    )\n",
    "    y_va_pred = model_nn.predict(X_va)\n",
    "    y_va_pred = np.argmax(y_va_pred, axis=1)\n",
    "    \n",
    "    #æ¤œè¨¼ç²¾åº¦ã‚’æ±‚ã‚ã‚‹\n",
    "    metric_va = f1_score(y_va, y_va_pred, average=\"macro\")\n",
    "    #metric_va = accuracy_score(y_va, y_va_pred)\n",
    "    return metric_va\n",
    "\n",
    "# æ¢ç´¢ã‚’å®Ÿè¡Œ\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print(\"æœ€ã‚‚é«˜ã„F1ã‚¹ã‚³ã‚¢\")\n",
    "print(trial.value)\n",
    "\n",
    "print(\"æœ€ã‚‚é«˜ã„ç²¾åº¦ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š\")\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€ã‚‚é«˜ã„F1ã‚¹ã‚³ã‚¢\n",
    "0.36939651107967936\n",
    "æœ€ã‚‚é«˜ã„ç²¾åº¦ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š\n",
    "{'du_01': 54, 'do_01': 0.2242068153855472, 'du_02': 75, 'do_02': 0.1846854267310607, 'du_03': 14, 'do_03': 0.1363224268344519, 'batch': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_best = trial.params\n",
    "#params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ã“ã“ã¾ã§å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_best = { 'DU_01': 54,\n",
    "                'DO_01': 0.224,\n",
    "                'DU_02': 75,\n",
    "                'DO_02': 0.18,\n",
    "                'DU_03': 14,\n",
    "                'DO_03': 0.13,\n",
    "                'BATCH': 100}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_best = { 'DU_01': 37,\n",
    "                'DO_01': 0.21901246292653168,\n",
    "                'DU_02': 56,\n",
    "                'DO_02': 0.18512176420345966,\n",
    "                'DU_03': 8,\n",
    "                'DO_03': 0.2931650271930273,\n",
    "                'BATCH': 92}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1],**params_best)\n",
    "model_nn.summary()\n",
    "result = model_nn.fit(X_tr, y_tr, batch_size=params_best[\"BATCH\"], epochs=15, validation_data=(X_va, y_va), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracyã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(result.history['accuracy'], label='train')\n",
    "plt.plot(result.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "# Lossã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure()\n",
    "plt.title('categorical_crossentropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(result.history['loss'], label='train')\n",
    "plt.plot(result.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model_nn.predict(X_tr)\n",
    "y_va_pred = model_nn.predict(X_va)\n",
    "\n",
    "#äºˆæ¸¬ç¢ºç‡ã‚’æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã«å¤‰æ›\n",
    "y_tr_pred = np.argmax(y_tr_pred, axis=1)\n",
    "y_va_pred = np.argmax(y_va_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«ç²¾åº¦:\")\n",
    "print(\"å­¦ç¿’ç²¾åº¦\")\n",
    "print(metric_tr)\n",
    "print(\"æ¤œè¨¼ç²¾åº¦\")\n",
    "\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "valid_f1 = f1_score(y_va, y_va_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "params_base = {\"boosting_type\":\"gbdt\",\n",
    "          \"objective\":\"multiclass\",\n",
    "          \"metric\":\"multi_logloss\",\n",
    "          \"num_class\":\"3\",\n",
    "          \"learning_rate\":0.01,\n",
    "          \"num_leaves\": 16,\n",
    "          \"n_estimators\":1000,\n",
    "          \"random_state\":123,\n",
    "          \"importance_type\":\"gain\",\n",
    "          \"early_stopping_round\":100,\n",
    "          \"verbose\":10\n",
    "          }\n",
    "\n",
    "\"\"\"\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§æ¢ç´¢ã™ã‚‹æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\":trial.suggest_int(\"min_data_in_leaf\", 5,200),\n",
    "        \"min_sum_hessian_in_leaf\":trial.suggest_float(\"min_sum_hessian_in_leaf\", 0.00001, 0.01, log = True),\n",
    "        \"feature_fraction\":trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\":trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\":trial.suggest_float(\"lambda_l1\", 0.01, 10.0, log = True),\n",
    "        \"lambda_l2\":trial.suggest_float(\"lambda_l2\", 0.01, 10.0, log = True)\n",
    "    }\n",
    "    \n",
    "    #tuningã«baseã®å€¤ã‚’åŠ ãˆã‚‹\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    #ãƒ¢ãƒ‡ãƒ«å­¦ç¿’(ãƒ™ã‚¤ã‚ºæœ€é©åŒ–)\n",
    "    list_metrics=[]\n",
    "    \n",
    "    # ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ¤œè¨¼ - å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†å‰²ã‚’1é€šã‚Šæ±ºã‚ã‚‹\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "        \n",
    "    model = lgb.LGBMClassifier(**params_tuning)\n",
    "        \n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)], \n",
    "                    #early_stopping_rounds=100, \n",
    "                    #verbose=0\n",
    "                    )\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    \n",
    "    #æ¤œè¨¼ç²¾åº¦ã‚’æ±‚ã‚ã‚‹\n",
    "    metric_va = f1_score(y_va, y_va_pred, average='macro')\n",
    "    #metric_va = accuracy_score(y_va, y_va_pred)\n",
    "    return metric_va\n",
    "\n",
    "# æ¢ç´¢ã‚’å®Ÿè¡Œ\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¢ç´¢ã§å¾—ã‚‰ã‚ŒãŸçµæœã‚’ç¢ºèª\n",
    "\"\"\"\n",
    "trial = study.best_trial\n",
    "print(\"æœ€ã‚‚é«˜ã„F1ã‚¹ã‚³ã‚¢\")\n",
    "print(trial.value)\n",
    "\n",
    "print(\"æœ€ã‚‚é«˜ã„ç²¾åº¦ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š\")\n",
    "print(trial.params)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€ã‚‚é«˜ã„ç²¾åº¦ï¼š\n",
    "0.7880910683012259\n",
    "æœ€ã‚‚é«˜ã„ç²¾åº¦ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š\n",
    "{'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.18591711878786357, 'lambda_l2': 8.755734725056497}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMã®ãƒ¢ãƒ‡ãƒ«\n",
    "\n",
    "model = lgb.LGBMClassifier(**params_base)\n",
    "model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)])\n",
    "\n",
    "\"\"\"\n",
    "model = lgb.LGBMClassifier(**params_best)\n",
    "model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUCå€¤ã«åŠ ãˆç²¾åº¦ã‚’ç®—å‡ºã™ã‚‹\n",
    "\n",
    "y_tr_pred = model.predict(X_tr)\n",
    "y_va_pred = model.predict(X_va)\n",
    "\n",
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«ç²¾åº¦:\")\n",
    "print(\"å­¦ç¿’ç²¾åº¦\")\n",
    "print(metric_tr)\n",
    "print(\"æ¤œè¨¼ç²¾åº¦\")\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "valid_predictions = model.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, valid_predictions, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "micro_f1 = f1_score(y_va, valid_predictions, average='micro')\n",
    "\n",
    "print(\"ãƒŸã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(micro_f1)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, valid_predictions)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯„ä¸ç‡ç®—å‡º\n",
    "# feature importanceã‚’è¡¨ç¤º\n",
    "# importanceã‚’è¡¨ç¤ºã™ã‚‹\n",
    "\n",
    "importance = pd.DataFrame(model.feature_importances_, index=X_tr.columns, columns=['importance'])\n",
    "impo02 = importance.sort_values(by=\"importance\")\n",
    "display(impo02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ã“ã“ã¾ã§å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems_TrunkOther\t0.000000\n",
    "problems_StonesTrunkOther\t2.406300\n",
    "problems_BranchOther\t10.268320\n",
    "steward_3or4\t13.906020\n",
    "problems_RootOtherTrunkOtherBranchOther\t20.130170\n",
    "steward_4orMore\t22.130930\n",
    "curb_loc_OnCurb\t26.089900\n",
    "problems_StonesRootOther\t29.473130\n",
    "steward_NULL\t31.843760\n",
    "sidewalk_NoDamage\t37.184240\n",
    "problems_StonesBranchOther\t38.574340\n",
    "curb_loc_OffsetFromCurb\t38.776410\n",
    "problems_BranchLights\t39.326430\n",
    "guards_Unsure\t40.097710\n",
    "problems_RootOther\t49.345920\n",
    "guards_Harmful\t54.356240\n",
    "\n",
    "problemsã¯æ®†ã©å¯„ä¸ã—ã¦ã„ãªã„ã‚‚ã®ã‚‚ã‚ã‚‹\n",
    "problems_TrunkOther\t0.000000\n",
    "problems_StonesTrunkOther\t2.406300\n",
    "problems_BranchOther\t10.268320\n",
    "problems_RootOtherTrunkOtherBranchOther\t20.130170\n",
    "problems_StonesRootOther\t29.473130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "reg = LazyClassifier(ignore_warnings=True, random_state=1121, verbose=False,predictions=True)\n",
    "models, predictions = reg.fit(X_tr, X_va, y_tr, y_va) \n",
    "\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ãƒ»è©•ä¾¡æŒ‡æ¨™ï¼š\")\n",
    "display(models)\n",
    "print(\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬å€¤ï¼š\")\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¿‘å‚ä¸­å¿ƒæ³•ã«ã‚ˆã‚‹äºˆæ¸¬ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿‘å‚ä¸­å¿ƒæ³•ã§å­¦ç¿’\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "\n",
    "model_nc = NearestCentroid()\n",
    "model_nc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_nc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_nc.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºã«ã‚ˆã‚‹äºˆæ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_gnb.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_gnb.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassiveAggressiveClassifierã«ã‚ˆã‚‹äºˆæ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "model_pac = PassiveAggressiveClassifier()\n",
    "model_pac.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_pac.predict(X_va)\n",
    "y_pred\n",
    "\n",
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_gnb.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆæ³•ã«ã‚ˆã‚‹äºˆæ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_rf.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_rf.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreeClassifierã‚’å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "model_etc = ExtraTreeClassifier()\n",
    "model_etc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_etc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifierã‚’å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dtc = DecisionTreeClassifier()\n",
    "model_dtc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_dtc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuadraticDiscriminantAnalysisã‚’å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€QuadraticDiscriminantAnalysisã‚’å­¦ç¿’\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "model_qda.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_qda.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€QuadraticDiscriminantAnalysisã‚’å­¦ç¿’\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_lda.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaggingClassifierã‚’å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€QuadraticDiscriminantAnalysisã‚’å­¦ç¿’\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_bc = BaggingClassifier()\n",
    "model_bc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_bc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"æ¯”é‡ä»˜ãç²¾åº¦ï¼š\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"ãƒã‚¯ãƒ­f1ã‚¹ã‚³ã‚¢ï¼š\")\n",
    "print(valid_f1)\n",
    "\n",
    "# æ··åˆè¡Œåˆ— - ãƒ©ãƒ™ãƒ«ã®æ­£èª¤ã®åˆ†é¡æ•°ã‚’ã¾ã¨ã‚ã‚‹\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"æ··åˆè¡Œåˆ—ï¼š\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æŠ•ç¨¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# èª¬æ˜å¤‰æ•°ãƒ»ç›®çš„å¤‰æ•°\n",
    "\n",
    "# æœˆãƒ»å¹´ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã«å«ã‚ã‚‹\n",
    "test[\"datetime\"] = pd.to_datetime(test[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "test[\"year\"] = test[\"datetime\"].dt.year\n",
    "test[\"month\"] = test[\"datetime\"].dt.month\n",
    "test[\"season\"] = pd.Categorical(test[\"month\"].apply(to_season))\n",
    "\n",
    "train.head(2)\n",
    "\n",
    "# problemsã‚’boolå¤‰æ› â†’ å•é¡ŒãŒã‚ã‚‹ã‹å¦ã‹ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«ã™ã‚‹\n",
    "test['bool_problems'] = test['problems'].apply(lambda x: 0 if x=='NULL' else 1)\n",
    "\n",
    "X_test = test[x_list]\n",
    "X_test\n",
    "\n",
    "# æ¬ æå€¤è£œå®Œ\n",
    "test.fillna('NULL', inplace=True)\n",
    "X_test.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns = dummy_list, drop_first=False)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸€æŒ™ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "for col in cols:\n",
    "    column_means = train.groupby(col)[\"health\"].mean(\"health\")\n",
    "    column_means\n",
    "    \n",
    "    colname = col + \"_tg_enc\"\n",
    "    \n",
    "    X_test[colname] = test[col].map(column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems, spc_commonã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
    "X_test = X_test.drop(drop_col , axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_test)\n",
    "X_test_std = pd.DataFrame(std_scaler.transform(X_test), columns=X_train.columns)\n",
    "X_test_std\n",
    "# X_train_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = X_test_std[list]\n",
    "X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬\n",
    "y_test_pred = model_gnb.predict(X_test_std)\n",
    "\n",
    "# NOTE äºˆæ¸¬çµæœã‚’1æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«ã™ã‚‹\n",
    "y_test_pred = np.squeeze(y_test_pred)\n",
    "y_test_pred.shape\n",
    "\n",
    "# NOTE äºˆæ¸¬çµæœã‚’pdã«ã—ã¦å‡¦ç†\n",
    "df_submit = pd.DataFrame(data=y_test_pred, columns=['y_pred'])\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit['y_pred'] = df_submit['y_pred'].map({0:1, 1:0, 2:2})\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = df_submit[\"y_pred\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit[1] = y_test_pred\n",
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#æœ¨ã®å¥åº·çŠ¶æ…‹ã‚’0ãƒ»1ã‚’ç½®ãæ›ãˆã‚‹\n",
    "#train['health'] = train['health'].map({0:1, 1:0, 2:2})\n",
    "#train\n",
    "\n",
    "sample_submit.to_csv('submit_25_GNB_DateData_Enc+Dammy+TMS_TEncOnly.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
