{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# 分布確認に使う\n",
    "#import pandas_profiling as pdp\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "# 前処理、特徴量作成 - sklearnを使う\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "# モデリング・精度と評価指標\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "#LGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# NOTE matplotでの日本語文字化けを解消\n",
    "#pip install japanize-matplotlib\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col=0) # 学習用データ\n",
    "test = pd.read_csv(\"test.csv\", index_col=0) # 学習用データ   # 評価用データ\n",
    "sample_submit = pd.read_csv(\"sample_submission.csv\", index_col=0, header=None) # 応募用サンプルファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "\n",
    "print(\"データ形状：\")\n",
    "print(train.shape)\n",
    "\n",
    "print(\"データ数：\")\n",
    "print(len(train))\n",
    "\n",
    "print(\"データのコラム数\")\n",
    "print(len(train.columns))\n",
    "\n",
    "print(\"データ型一覧\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コラム数は全部で20個。ダミー化できるものはダミー化、そうでないものは分布数の多いもののみを取り出すなどの工夫をして\n",
    "ドメイン知識を使った特徴量エンジニアリングをする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"データ型一覧\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree_dbh, health, borocode, boro_ct, cb_num, st_senate, st_assem, cncldistで\n",
    "ベースラインを作成する。その他本来ならint型にするべき値もベースラインに用いる\n",
    "\n",
    "tree_dbh - 木の円周。量的変数\n",
    "health - 木の健康状態、目的変数\n",
    "borocode - ニューヨークの行政区分。質的変数\n",
    "boro_ct - ニューヨーク市の行政区分（ボロー）の名称。質的変数\n",
    "cb_num - コミュニティボード番号。質的変数\n",
    "st_senate - 州上院地区番号。質的変数\n",
    "st_assem - 州議会地区番号。質的変数\n",
    "cncldist - 市議会の地区番号。質的変数\n",
    "\n",
    "→使えるのはtree_dbhだけ。\n",
    "次はstr・object型からint・float型に変換するべきものを探す\n",
    "\n",
    "steward → 木の管理者数 \n",
    "stewardはダミー化する。\n",
    "\n",
    "tree_dbh,stewardの他にもまずは簡単にダミー化できる変数5つを使ってベースを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"データのコラム数\")\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"データのコラム数\")\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"health\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.plot.bar(\"health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的変数は1(good)であることが殆どだが、0や2(normal, bad)が約20%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"curb_loc\"].value_counts()\n",
    "print(counts)\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"curb_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"steward\"].value_counts()\n",
    "print(counts)\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"steward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"guards\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"guards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"sidewalk\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"sidewalk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"user_type\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"user_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tree_dbh\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ ポアソン分布に近い。指数化すればより有効な値になるかも？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "counts = train[\"problems\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "counts = counts.sort_index()\n",
    "counts.plot.bar(\"problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分布を確認\n",
    "prob_counts = train[\"problems\"].value_counts()\n",
    "print(prob_counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "prob_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_counts = train[\"spc_common\"].value_counts()\n",
    "print(spc_counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "spc_counts.plot.bar(\"spc_common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 木の種類 - 最初の10をダミー化する\n",
    "counts[:15].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train[\"spc_latin\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"spc_latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 木の種類 - 最初の10をダミー化する\n",
    "counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#地域（Neighborhood Tabulation Area）の略称\n",
    "counts = train[\"nta\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"nta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#地域（Neighborhood Tabulation Area）の略称\n",
    "counts = train[\"nta_name\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"nta_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vill, beach, side, hill, park, water, bay, gardenなど木に影響しそうな名称を抽出するか？？\n",
    "counts[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ニューヨーク市の行政区分（ボロー）のコード\n",
    "#ボロコードは非常に有益そう。量的変数にする\n",
    "counts = train[\"borocode\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"borocode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train[\"boro_ct\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"boro_ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ニューヨーク市の行政区分（ボロー）の名称\n",
    "#　ボロー名称は有効そう。ダミー変数にする\n",
    "\n",
    "counts = train[\"boroname\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"boroname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　郵便番号に関連する都市または地区\n",
    "#　最初の5-10個をダミー化するか??\n",
    "# 頻度を量的変数にする、などより有効なダミー化も検討中\n",
    "\n",
    "counts = train[\"zip_city\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"zip_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ニューヨーク市の行政区分（ボロー）の名称\n",
    "#　ボロー名称は有効そう。ダミー変数にする\n",
    "\n",
    "counts = train[\"cb_num\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"cb_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ニューヨーク市の行政区分（ボロー）の名称\n",
    "#　ボロー名称は有効そう。ダミー変数にする\n",
    "\n",
    "counts = train[\"st_senate\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"st_senate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ニューヨーク市の行政区分（ボロー）の名称\n",
    "#　ボロー名称は有効そう。ダミー変数にする\n",
    "\n",
    "counts = train[\"st_assem\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"st_assem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ニューヨーク市の行政区分（ボロー）の名称\n",
    "#　ボロー名称は有効そう。ダミー変数にする\n",
    "\n",
    "counts = train[\"cncldist\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "#counts = counts.sort_index()\n",
    "counts.plot.bar(\"cncldist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベースライン作成に用いる変数\n",
    "tree_dbh\n",
    "curb_loc\n",
    "steward\n",
    "guards\n",
    "sidewalk\n",
    "user_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時期列データ\n",
    "・記録された年・月を分析に含める\n",
    "・季節を説明変数に含める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"データ型一覧\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"datetime\"] = pd.to_datetime(train[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#年・月を取得\n",
    "train[\"datetime\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year\"] = train[\"datetime\"].dt.year\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"month\"] = train[\"datetime\"].dt.month\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year_month\"] = train[\"datetime\"].dt.strftime(\"%Y-%m\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE 年月を季節に変換\n",
    "def to_season(num):\n",
    "    season = \"winter\"\n",
    "    if (3 <= num <= 5):\n",
    "        season = \"spring\"\n",
    "    elif (6 <= num <= 8):\n",
    "        season = \"summer\"\n",
    "    elif (9 <= num <= 11):\n",
    "        season = \"autumn\"\n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"season\"] = pd.Categorical(train[\"month\"].apply(to_season))\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [\"tree_dbh\",\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"bool_problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\",\"season\"]\n",
    "# x_list = [\"tree_dbh\",\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"bool_problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\"]\n",
    "y_list = [\"health\"]\n",
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンダーサンプリング\n",
    "過学習対策としてtrain['health']から1の数を減らす\n",
    "→ この方法は逆効果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = train['health'].value_counts()\n",
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1の割合：\")\n",
    "print(\"\" + str(float( train_values[1] / train['health'].value_counts().sum() ) * 100) + \" %\")\n",
    "\n",
    "print(\"0の割合：\")\n",
    "print(\"\" + str(float( train_values[0] / train['health'].value_counts().sum() ) * 100) + \" %\")\n",
    "\n",
    "print(\"2の割合：\")\n",
    "print(\"\" + str(float( train_values[2] / train['health'].value_counts().sum() ) * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 木の健康状態（目的変数）\n",
    "0:Fair（普通） 1:Good（良い） 2:Poor（悪い）\n",
    "0:良い、1:普通、2:悪い、という値に置き換える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['health'] = train['health'].map({0:1, 1:0, 2:2})\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problemsをbool変換 → 問題があるか否かのダミー変数にする\n",
    "train['bool_problems'] = train['problems'].apply(lambda x: 0 if x=='NULL' else 1)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　説明変数+目的変数とバリデーション設計\n",
    "X_train, y_train = train[x_list], train[y_list]\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"datetime\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"year\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"month\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"year_month\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "木の状態は冬・梅雨・夏開けに悪くなる?\n",
    "\n",
    "→その月のニューヨークの平均気温・平均湿度・平均降水量などを分析要因に加える\n",
    "5,6,9,10,1,2に状態の悪い木が増えるのが共通している！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"season\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→　欠損値は'NULL'というカテゴリに置き換え、欠損であるという情報=質的変数の1つとして処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = train.groupby(\"steward\")[\"health\"].mean(\"health\")\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンダーサンプリング実行\n",
    "0の数を半分に削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "strategy = {0:7500, 1:3535, 2:698}\n",
    "\n",
    "sample_exe = RandomUnderSampler(random_state=0, sampling_strategy = strategy)\n",
    "X_resampled, y_resampled = sample_exe.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　木の直径とhealthの関係\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='health', y='tree_dbh', data=train)\n",
    "plt.title('木の円周・木の健康状態の箱ひげ図')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ badな木は若干円周が大きい。育ちすぎ等の原因があるかもしれない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回の特徴量エンジニアリング\n",
    "\n",
    "x_list = [\"tree_dbh\", \"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]\n",
    "y_list = [\"health\"]\n",
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]\n",
    "\n",
    "- [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\"]をダミー化する\n",
    "- \"problems\"をダミー化する。その際最初の10行だけを残す\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 少数の質的変数をダミー化\n",
    "[\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"borocode\",\"season\"]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns = dummy_list, drop_first=False)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質的変数をターゲットエンコーディング\n",
    "まず各コラムの平均値を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一挙にターゲットエンコーディング\n",
    "cols = [\"curb_loc\",\"steward\",\"guards\",\"sidewalk\",\"user_type\",\"problems\",\"spc_common\",\"nta\",\"borocode\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\"]\n",
    "for col in cols:\n",
    "    column_means = train.groupby(col)[\"health\"].mean(\"health\")\n",
    "    column_means\n",
    "    \n",
    "    colname = col + \"_tg_enc\"\n",
    "    \n",
    "    X_train[colname] = train[col].map(column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems, spc_commonをドロップアウト\n",
    "drop_col = [\"problems\",\"spc_common\",\"nta\",\"boro_ct\", \"zip_city\", \"cb_num\", \"st_senate\", \"st_assem\", \"cncldist\",\"year\",\"month\"]\n",
    "\n",
    "X_train = X_train.drop(drop_col , axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "colormap = plt.cm.RdBu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr, square=True, \n",
    "            cmap=colormap, \n",
    "            linecolor='white', annot=False,\n",
    "            vmin=1.0, vmax=-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オーバーサンプリング\n",
    "等倍にするオーバーサンプリングでは逆効果。\n",
    "1, 2の数を倍にして精度向上するかを検証する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "strategy = {0:15751, 1:3535*2, 2:698*2}\n",
    "sm = SMOTE(sampling_strategy = strategy)\n",
    "\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()\n",
    "\n",
    "X_train, y_train = X_resampled, y_resampled\n",
    "X_train.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_std = pd.DataFrame(std_scaler.transform(X_train), columns=X_train.columns)\n",
    "X_train_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量選択\n",
    "学習に使う特徴量を絞る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# estimatorとしてGBDTを使用。特徴量を20個選択\n",
    "selector = RFE(GradientBoostingRegressor(n_estimators=100, random_state=10), n_features_to_select=35)\n",
    "selector.fit(X_train_std, y_train)\n",
    "mask = selector.get_support()\n",
    "#print(X.feature_names)\n",
    "print(mask)\n",
    "\n",
    "# 選択した特徴量の列のみ取得\n",
    "X_selected = selector.transform(X_train_std)\n",
    "print(\"X.shape={}, X_selected.shape={}\".format(X_train_std.shape, X_selected.shape))\n",
    "\n",
    "list = []\n",
    "not_selected = []\n",
    "columns = X_train_std.columns\n",
    "\n",
    "for i in range(0, len(mask)):\n",
    "    \n",
    "    value = mask[i]\n",
    "    \n",
    "    if (value == True):\n",
    "        list.append(columns[i])\n",
    "    else:\n",
    "        not_selected.append(columns[i])\n",
    "\n",
    "print(\"選択された25の特徴量：\")\n",
    "print(list)\n",
    "\n",
    "print(\"選択されなかった特徴量：\")\n",
    "print(not_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'boro_ct_tg_enc'をリストから省く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25に絞ったX_train_stdの変数を次元圧縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "X_pca = pca.fit_transform(X_train_std)\n",
    "X_pca.shape\n",
    "\n",
    "X_tsne_nc = TSNE(learning_rate = 100).fit_transform(X_train_std)\n",
    "print(X_tsne_nc[:5, :5])\n",
    "print(\"--- X_tsne_nopca ---\")\n",
    "\n",
    "X_tsne = TSNE(learning_rate = 100).fit_transform(X_pca)\n",
    "print(X_tsne[:5, :5])\n",
    "print(\"--- X_tsne ---\")\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.scatter(X_train_std[\"tree_dbh\"], X_train_std[\"problems_tg_enc\"],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(X_tsne_nc[:,0], X_tsne_nc[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.scatter(X_train_std[\"tree_dbh\"], X_train_std[\"problems_tg_enc\"],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.scatter(X_tsne_nc[:,0], X_tsne_nc[:,1],color = \"blue\", alpha = 0.25)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1],c = y_train[\"health\"], alpha = 0.25,cmap='plasma')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1],c = y_train[\"health\"], alpha = 0.25,cmap='plasma')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ホールドアウト検証 - 学習用・テスト用の分割を1通り決める\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_train_std[list], y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "print(\"学習用・訓練用データの形状：\")\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(X_va.shape)\n",
    "print(y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ホールドアウト検証(次元圧縮した🅂データ)\n",
    "X_tr_dr, X_va_dr, y_tr_dr, y_va_dr = train_test_split(X_tsne, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "print(\"学習用・訓練用データの形状：\")\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(X_va.shape)\n",
    "print(y_va.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークによる学習 + モデル最適化\n",
    "def model_neuralnet(INPUT_SHAPE = X_tr.shape[1]):\n",
    "    \n",
    "    # パラメータ\n",
    "    DU_01 = 50\n",
    "    DO_01 = 0.3\n",
    "    DU_02 = 50\n",
    "    DO_02 = 0.2\n",
    "    DU_03 = 10\n",
    "    DO_03 = 0.1\n",
    "    \n",
    "    input_num = Input(shape = (INPUT_SHAPE, ))\n",
    "    \n",
    "    x_num = Dense(DU_01, activation = \"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_01)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_02, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_02)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_03, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_03)(x_num)\n",
    "    \n",
    "    out = Dense(3, activation = \"softmax\")(x_num)\n",
    "    model = Model(inputs = input_num, outputs = out, )\n",
    "    model.compile(optimizer = \"Adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model_nn = model_neuralnet()\n",
    "model_nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_nn.fit(X_tr, y_tr, batch_size=200, epochs=20, validation_data=(X_va, y_va), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracyのプロット\n",
    "plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(result.history['accuracy'], label='train')\n",
    "plt.plot(result.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "# Lossのプロット\n",
    "plt.figure()\n",
    "plt.title('categorical_crossentropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(result.history['loss'], label='train')\n",
    "plt.plot(result.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model_nn.predict(X_tr)\n",
    "y_va_pred = model_nn.predict(X_va)\n",
    "\n",
    "#予測確率を最も可能性の高いクラスに変換\n",
    "y_tr_pred = np.argmax(y_tr_pred, axis=1)\n",
    "y_va_pred = np.argmax(y_va_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"モデル精度:\")\n",
    "print(\"学習精度\")\n",
    "print(metric_tr)\n",
    "print(\"検証精度\")\n",
    "\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "valid_f1 = f1_score(y_va, y_va_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークによる学習 + モデル最適化\n",
    "def model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1], DU_01=50, DO_01=0.3, DU_02=50, DO_02=0.2, DU_03=10, DO_03=0.1,BATCH=32):\n",
    "    \n",
    "    # パラメータ\n",
    "    \"\"\"\n",
    "    DU_01 = 50\n",
    "    DO_01 = 0.3\n",
    "    DU_02 = 50\n",
    "    DO_02 = 0.2\n",
    "    DU_03 = 10\n",
    "    DO_03 = 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    input_num = Input(shape = (INPUT_SHAPE, ))\n",
    "    \n",
    "    x_num = Dense(DU_01, activation = \"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_01)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_02, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_02)(x_num)\n",
    "    \n",
    "    x_num = Dense(DU_03, activation = \"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    X_num = Dropout(DO_03)(x_num)\n",
    "    \n",
    "    out = Dense(3, activation = \"softmax\")(x_num)\n",
    "    model = Model(inputs = input_num, outputs = out, )\n",
    "    model.compile(optimizer = \"Adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    \n",
    "# マクロf1スコアを最大化させる\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# チューニングで探索する最適パラメータ\n",
    "    params_tuning = {\n",
    "        \"DU_01\": trial.suggest_int(\"DU_01\", 10, 100),\n",
    "        \"DO_01\":trial.suggest_float(\"DO_01\", 0.1, 0.3),\n",
    "        \"DU_02\": trial.suggest_int(\"DU_02\", 10, 100),\n",
    "        \"DO_02\":trial.suggest_float(\"DO_02\", 0.1, 0.3),\n",
    "        \"DU_03\": trial.suggest_int(\"DU_03\", 3, 30),\n",
    "        \"DO_03\":trial.suggest_float(\"DO_03\", 0.1, 0.3),\n",
    "        \n",
    "        \"BATCH\": trial.suggest_int(\"batch\", 64, 128),\n",
    "        # \"optimizer\":trial.suggest_categorical(\"optimizer\",[\"Adam\",\"SGD\"])\n",
    "    }\n",
    "\n",
    "    # ホールドアウト検証 - 学習用・テスト用の分割を1通り決める\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X_train[list], y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "        \n",
    "    # モデルの学習\n",
    "    model_nn = model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1], **params_tuning)\n",
    "    #model_nn.summary()\n",
    "        \n",
    "    model_nn.fit(X_tr, y_tr, batch_size=params_tuning[\"BATCH\"], epochs=20, validation_data=(X_va, y_va), verbose=1\n",
    "                    #early_stopping_rounds=100, \n",
    "                    #verbose=0\n",
    "                    )\n",
    "    y_va_pred = model_nn.predict(X_va)\n",
    "    y_va_pred = np.argmax(y_va_pred, axis=1)\n",
    "    \n",
    "    #検証精度を求める\n",
    "    metric_va = f1_score(y_va, y_va_pred, average=\"macro\")\n",
    "    #metric_va = accuracy_score(y_va, y_va_pred)\n",
    "    return metric_va\n",
    "\n",
    "# 探索を実行\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print(\"最も高いF1スコア\")\n",
    "print(trial.value)\n",
    "\n",
    "print(\"最も高い精度となるパラメータ：\")\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も高いF1スコア\n",
    "0.36939651107967936\n",
    "最も高い精度となるパラメータ：\n",
    "{'du_01': 54, 'do_01': 0.2242068153855472, 'du_02': 75, 'do_02': 0.1846854267310607, 'du_03': 14, 'do_03': 0.1363224268344519, 'batch': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_best = trial.params\n",
    "#params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ここまで実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_best = { 'DU_01': 54,\n",
    "                'DO_01': 0.224,\n",
    "                'DU_02': 75,\n",
    "                'DO_02': 0.18,\n",
    "                'DU_03': 14,\n",
    "                'DO_03': 0.13,\n",
    "                'BATCH': 100}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_best = { 'DU_01': 37,\n",
    "                'DO_01': 0.21901246292653168,\n",
    "                'DU_02': 56,\n",
    "                'DO_02': 0.18512176420345966,\n",
    "                'DU_03': 8,\n",
    "                'DO_03': 0.2931650271930273,\n",
    "                'BATCH': 92}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = model_neuralnet_optimized(INPUT_SHAPE = X_tr.shape[1],**params_best)\n",
    "model_nn.summary()\n",
    "result = model_nn.fit(X_tr, y_tr, batch_size=params_best[\"BATCH\"], epochs=15, validation_data=(X_va, y_va), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracyのプロット\n",
    "plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(result.history['accuracy'], label='train')\n",
    "plt.plot(result.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "# Lossのプロット\n",
    "plt.figure()\n",
    "plt.title('categorical_crossentropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(result.history['loss'], label='train')\n",
    "plt.plot(result.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model_nn.predict(X_tr)\n",
    "y_va_pred = model_nn.predict(X_va)\n",
    "\n",
    "#予測確率を最も可能性の高いクラスに変換\n",
    "y_tr_pred = np.argmax(y_tr_pred, axis=1)\n",
    "y_va_pred = np.argmax(y_va_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"モデル精度:\")\n",
    "print(\"学習精度\")\n",
    "print(metric_tr)\n",
    "print(\"検証精度\")\n",
    "\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "valid_f1 = f1_score(y_va, y_va_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMのパラメータ\n",
    "params_base = {\"boosting_type\":\"gbdt\",\n",
    "          \"objective\":\"multiclass\",\n",
    "          \"metric\":\"multi_logloss\",\n",
    "          \"num_class\":\"3\",\n",
    "          \"learning_rate\":0.01,\n",
    "          \"num_leaves\": 16,\n",
    "          \"n_estimators\":1000,\n",
    "          \"random_state\":123,\n",
    "          \"importance_type\":\"gain\",\n",
    "          \"early_stopping_round\":100,\n",
    "          \"verbose\":10\n",
    "          }\n",
    "\n",
    "\"\"\"\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "# チューニングで探索する最適パラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\":trial.suggest_int(\"min_data_in_leaf\", 5,200),\n",
    "        \"min_sum_hessian_in_leaf\":trial.suggest_float(\"min_sum_hessian_in_leaf\", 0.00001, 0.01, log = True),\n",
    "        \"feature_fraction\":trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\":trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\":trial.suggest_float(\"lambda_l1\", 0.01, 10.0, log = True),\n",
    "        \"lambda_l2\":trial.suggest_float(\"lambda_l2\", 0.01, 10.0, log = True)\n",
    "    }\n",
    "    \n",
    "    #tuningにbaseの値を加える\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    #モデル学習(ベイズ最適化)\n",
    "    list_metrics=[]\n",
    "    \n",
    "    # ホールドアウト検証 - 学習用・テスト用の分割を1通り決める\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=123)\n",
    "\n",
    "        \n",
    "    model = lgb.LGBMClassifier(**params_tuning)\n",
    "        \n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)], \n",
    "                    #early_stopping_rounds=100, \n",
    "                    #verbose=0\n",
    "                    )\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    \n",
    "    #検証精度を求める\n",
    "    metric_va = f1_score(y_va, y_va_pred, average='macro')\n",
    "    #metric_va = accuracy_score(y_va, y_va_pred)\n",
    "    return metric_va\n",
    "\n",
    "# 探索を実行\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索で得られた結果を確認\n",
    "\"\"\"\n",
    "trial = study.best_trial\n",
    "print(\"最も高いF1スコア\")\n",
    "print(trial.value)\n",
    "\n",
    "print(\"最も高い精度となるパラメータ：\")\n",
    "print(trial.params)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も高い精度：\n",
    "0.7880910683012259\n",
    "最も高い精度となるパラメータ：\n",
    "{'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.18591711878786357, 'lambda_l2': 8.755734725056497}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMのモデル\n",
    "\n",
    "model = lgb.LGBMClassifier(**params_base)\n",
    "model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)])\n",
    "\n",
    "\"\"\"\n",
    "model = lgb.LGBMClassifier(**params_best)\n",
    "model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_va, y_va)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC値に加え精度を算出する\n",
    "\n",
    "y_tr_pred = model.predict(X_tr)\n",
    "y_va_pred = model.predict(X_va)\n",
    "\n",
    "metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "metric_va = accuracy_score(y_va, y_va_pred)\n",
    "print(\"モデル精度:\")\n",
    "print(\"学習精度\")\n",
    "print(metric_tr)\n",
    "print(\"検証精度\")\n",
    "print(metric_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "valid_predictions = model.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, valid_predictions, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "micro_f1 = f1_score(y_va, valid_predictions, average='micro')\n",
    "\n",
    "print(\"ミクロf1スコア：\")\n",
    "print(micro_f1)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, valid_predictions)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_va_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寄与率算出\n",
    "# feature importanceを表示\n",
    "# importanceを表示する\n",
    "\n",
    "importance = pd.DataFrame(model.feature_importances_, index=X_tr.columns, columns=['importance'])\n",
    "impo02 = importance.sort_values(by=\"importance\")\n",
    "display(impo02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ここまで実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems_TrunkOther\t0.000000\n",
    "problems_StonesTrunkOther\t2.406300\n",
    "problems_BranchOther\t10.268320\n",
    "steward_3or4\t13.906020\n",
    "problems_RootOtherTrunkOtherBranchOther\t20.130170\n",
    "steward_4orMore\t22.130930\n",
    "curb_loc_OnCurb\t26.089900\n",
    "problems_StonesRootOther\t29.473130\n",
    "steward_NULL\t31.843760\n",
    "sidewalk_NoDamage\t37.184240\n",
    "problems_StonesBranchOther\t38.574340\n",
    "curb_loc_OffsetFromCurb\t38.776410\n",
    "problems_BranchLights\t39.326430\n",
    "guards_Unsure\t40.097710\n",
    "problems_RootOther\t49.345920\n",
    "guards_Harmful\t54.356240\n",
    "\n",
    "problemsは殆ど寄与していないものもある\n",
    "problems_TrunkOther\t0.000000\n",
    "problems_StonesTrunkOther\t2.406300\n",
    "problems_BranchOther\t10.268320\n",
    "problems_RootOtherTrunkOtherBranchOther\t20.130170\n",
    "problems_StonesRootOther\t29.473130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "reg = LazyClassifier(ignore_warnings=True, random_state=1121, verbose=False,predictions=True)\n",
    "models, predictions = reg.fit(X_tr, X_va, y_tr, y_va) \n",
    "\n",
    "print(\"モデルの精度・評価指標：\")\n",
    "display(models)\n",
    "print(\"テストデータの予測値：\")\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 近傍中心法による予測 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 近傍中心法で学習\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "\n",
    "model_nc = NearestCentroid()\n",
    "model_nc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_nc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_nc.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ガウシアンナイーブベイズによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_gnb.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_gnb.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassiveAggressiveClassifierによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "model_pac = PassiveAggressiveClassifier()\n",
    "model_pac.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_pac.predict(X_va)\n",
    "y_pred\n",
    "\n",
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_gnb.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ランダムフォレスト法による予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_rf.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "valid_predictions = model_rf.predict(X_va)\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreeClassifierを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "model_etc = ExtraTreeClassifier()\n",
    "model_etc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_etc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifierを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dtc = DecisionTreeClassifier()\n",
    "model_dtc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_dtc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuadraticDiscriminantAnalysisを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　QuadraticDiscriminantAnalysisを学習\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "model_qda.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_qda.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　QuadraticDiscriminantAnalysisを学習\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_lda.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaggingClassifierを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　QuadraticDiscriminantAnalysisを学習\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_bc = BaggingClassifier()\n",
    "model_bc.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = model_bc.predict(X_va)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_score = balanced_accuracy_score(y_va, y_pred)\n",
    "\n",
    "print(\"比重付き精度：\")\n",
    "print(bas_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "valid_f1 = f1_score(y_va, y_pred, average='macro')\n",
    "\n",
    "print(\"マクロf1スコア：\")\n",
    "print(valid_f1)\n",
    "\n",
    "# 混合行列 - ラベルの正誤の分類数をまとめる\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_va)\n",
    "print(\"混合行列：\")\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 投稿用データを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数・目的変数\n",
    "\n",
    "# 月・年データを分析に含める\n",
    "test[\"datetime\"] = pd.to_datetime(test[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "test[\"year\"] = test[\"datetime\"].dt.year\n",
    "test[\"month\"] = test[\"datetime\"].dt.month\n",
    "test[\"season\"] = pd.Categorical(test[\"month\"].apply(to_season))\n",
    "\n",
    "train.head(2)\n",
    "\n",
    "# problemsをbool変換 → 問題があるか否かのダミー変数にする\n",
    "test['bool_problems'] = test['problems'].apply(lambda x: 0 if x=='NULL' else 1)\n",
    "\n",
    "X_test = test[x_list]\n",
    "X_test\n",
    "\n",
    "# 欠損値補完\n",
    "test.fillna('NULL', inplace=True)\n",
    "X_test.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns = dummy_list, drop_first=False)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一挙にターゲットエンコーディング\n",
    "for col in cols:\n",
    "    column_means = train.groupby(col)[\"health\"].mean(\"health\")\n",
    "    column_means\n",
    "    \n",
    "    colname = col + \"_tg_enc\"\n",
    "    \n",
    "    X_test[colname] = test[col].map(column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems, spc_commonをドロップアウト\n",
    "X_test = X_test.drop(drop_col , axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_test)\n",
    "X_test_std = pd.DataFrame(std_scaler.transform(X_test), columns=X_train.columns)\n",
    "X_test_std\n",
    "# X_train_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = X_test_std[list]\n",
    "X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "y_test_pred = model_gnb.predict(X_test_std)\n",
    "\n",
    "# NOTE 予測結果を1次元ベクトルにする\n",
    "y_test_pred = np.squeeze(y_test_pred)\n",
    "y_test_pred.shape\n",
    "\n",
    "# NOTE 予測結果をpdにして処理\n",
    "df_submit = pd.DataFrame(data=y_test_pred, columns=['y_pred'])\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit['y_pred'] = df_submit['y_pred'].map({0:1, 1:0, 2:2})\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = df_submit[\"y_pred\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit[1] = y_test_pred\n",
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#木の健康状態を0・1を置き換える\n",
    "#train['health'] = train['health'].map({0:1, 1:0, 2:2})\n",
    "#train\n",
    "\n",
    "sample_submit.to_csv('submit_25_GNB_DateData_Enc+Dammy+TMS_TEncOnly.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
